# research_agent/chatbot.py
from typing import Generator, Optional, Any
import google.generativeai as genai

class ResearchChatbot:
    """
    Gemini-backed chatbot helper.

    Methods:
      - answer(question) -> str                # non-streaming safe answer
      - stream_answer(question) -> generator   # yields text chunks (if streaming supported)
    """

    def __init__(self, model, context: str = ""):
        self.model = model
        self.context = context or ""

    def set_context(self, context: str):
        self.context = context or ""

    def _make_prompt(self, question: str) -> str:
        return (
            "You are a concise research assistant. Use ONLY the provided context to answer the question.\n\n"
            f"Context:\n{self.context}\n\n"
            f"User question: {question}\n\n"
            "Answer concisely (1-3 short paragraphs). If the information is not present in the context, "
            "respond exactly: \"This information is not available in the current research results.\""
        )

    def _parse_response(self, resp: Any) -> Optional[str]:
        """
        Robustly extract text from Gemini response object or from dict-like responses.
        Returns None if nothing usable is found.
        """
        try:
            # 1) Quick accessor .text (if present and non-empty)
            if hasattr(resp, "text") and resp.text:
                return str(resp.text).strip()

            # 2) candidates -> candidate -> content -> parts -> text
            if hasattr(resp, "candidates") and resp.candidates:
                cand = resp.candidates[0]
                # candidate may expose .content with parts
                if hasattr(cand, "content"):
                    parts = getattr(cand.content, "parts", None)
                    if parts:
                        texts = []
                        for p in parts:
                            if hasattr(p, "text") and p.text:
                                texts.append(p.text)
                        if texts:
                            return "".join(texts).strip()
                # fallback: candidate might be dict-like
                try:
                    cand_dict = cand if isinstance(cand, dict) else None
                    if cand_dict:
                        content = cand_dict.get("content")
                        if isinstance(content, list):
                            texts = []
                            for part in content:
                                if isinstance(part, dict):
                                    t = part.get("text") or part.get("content") or ""
                                    if t:
                                        texts.append(t)
                            if texts:
                                return "".join(texts).strip()
                except Exception:
                    pass

            # 3) dict-like response general fallback
            if isinstance(resp, dict):
                # Try common nested keys
                for key in ("output", "candidates", "response", "result"):
                    if key in resp:
                        val = resp[key]
                        # if candidates list
                        if isinstance(val, list) and val:
                            first = val[0]
                            if isinstance(first, dict):
                                # try to get text content
                                if "content" in first and isinstance(first["content"], list):
                                    texts = [p.get("text","") for p in first["content"] if isinstance(p, dict)]
                                    if any(texts):
                                        return "".join(texts).strip()
                                if "text" in first:
                                    return str(first["text"]).strip()
                        # if val is a string
                        if isinstance(val, str) and val.strip():
                            return val.strip()
                # last resort: stringified dict
                return str(resp).strip()
        except Exception:
            pass
        return None

    def answer(self, question: str) -> str:
        """Non-streaming answer fallback. Returns a string (never raises)."""
        prompt = self._make_prompt(question)
        try:
            resp = self.model.generate_content(prompt)  # do not pass unsupported kwargs
            parsed = self._parse_response(resp)
            if parsed:
                return parsed
            # If nothing parsed, return safe fallback message
            return "⚠️ No valid response generated by the model."
        except Exception as e:
            return f"⚠️ Error generating response: {e}"

    def stream_answer(self, question: str) -> Generator[str, None, None]:
        """
        Yields text chunks from Gemini if streaming is supported.
        If streaming isn't supported or errors, yields single error/fallback chunk.
        """
        prompt = self._make_prompt(question)
        try:
            for chunk in self.model.generate_content(prompt, stream=True):
                # chunk may be object with .text, or dict-like
                text = ""
                if hasattr(chunk, "text") and chunk.text:
                    text = str(chunk.text)
                elif isinstance(chunk, dict):
                    # common dict keys
                    text = chunk.get("text") or chunk.get("generated_text") or ""
                    if not text:
                        # try candidate-style chunks
                        candidates = chunk.get("candidates")
                        if isinstance(candidates, list) and candidates:
                            cand0 = candidates[0]
                            if isinstance(cand0, dict):
                                content = cand0.get("content")
                                if isinstance(content, list):
                                    pieces = [p.get("text","") for p in content if isinstance(p, dict)]
                                    text = "".join(pieces)
                if text:
                    yield text
        except Exception as e:
            # yield a single chunk describing error (caller will append)
            yield f"[Error while streaming response: {e}]"
